import streamlit as st
import pandas as pd
from dotenv import load_dotenv

# Load Local Environment keys
load_dotenv()

from monday_api import fetch_board_data
from data_processing import process_data, calculate_metrics
from ai_agent import get_ai_agent, ask_agent

# Monday.com Config
DEALS_BOARD_ID = "5026839660"
WO_BOARD_ID = "5026839625"

st.set_page_config(
    page_title="AI BI Dashboard",
    page_icon="üìä",
    layout="wide",
    initial_sidebar_state="expanded"
)

# Apply sleek styling
st.markdown("""
    <style>
    .stMetric {
        background-color: #f8f9fa;
        padding: 15px;
        border-radius: 10px;
        border-left: 5px solid #0052cc;
        box-shadow: 2px 2px 5px rgba(0,0,0,0.05);
    }
    .stMetric label {
        color: #5e6c84 !important;
        font-weight: 600;
        font-size: 14px;
    }
    .stMetric .metric-value {
        color: #172b4d !important;
        font-weight: 800;
        font-size: 28px;
    }
    h1 {
        color: #0052cc;
    }
    </style>
""", unsafe_allow_html=True)

st.title("üìä AI Business Intelligence Agent")
st.markdown("**Real-time Insights from Monday.com Work Orders & Deals**")

import concurrent.futures

@st.cache_data(ttl=300) # Cache for 5 mins to prevent API spamming
def load_and_clean_monday_data():
    with st.spinner("Fetching live data from Monday.com GraphQL API concurrently..."):
        # Fetch both boards simultaneously to cut loading time in half
        with concurrent.futures.ThreadPoolExecutor() as executor:
            future_deals = executor.submit(fetch_board_data, DEALS_BOARD_ID)
            future_wo = executor.submit(fetch_board_data, WO_BOARD_ID)
            
            deals_raw = future_deals.result()
            wo_raw = future_wo.result()

        deals_clean = process_data(deals_raw, board_type="deals")
        wo_clean = process_data(wo_raw, board_type="work_orders")

        metrics = calculate_metrics(deals_clean, wo_clean)

        return deals_clean, wo_clean, metrics

try:
    deals_df, wo_df, metrics = load_and_clean_monday_data()
except Exception as e:
    st.error(f"Critical error loading data: {str(e)}")
    deals_df, wo_df, metrics = pd.DataFrame(), pd.DataFrame(), {}

# Top Dashboard Metrics
col1, col2, col3, col4 = st.columns(4)
col1.metric("üí∞ Total Pipeline Value", f"${metrics.get('Total Pipeline Value', 0):,.2f}")
col2.metric("üéØ Expected Revenue", f"${metrics.get('Expected Revenue', 0):,.2f}")
col3.metric("üìã Work Order Completion", metrics.get('Work Order Completion Rate', '0%'))
col4.metric("üëë Top Sector", metrics.get('Top Sector', 'Unknown'))

st.divider()

# Left Column (Chat) and Right Column (Summary & Data)
main_col, side_col = st.columns([2, 1])

# --- Chat Interface ---
with main_col:
    st.subheader("üí¨ Ask the AI BI Agent")
    st.markdown("Example questions: *'Which sector generates the highest revenue?'* or *'What is our work order completion rate?'*")
    
    query = st.text_input("Enter your business question:", placeholder="e.g. How is our pipeline looking this quarter?")
    
    if query:
        agent = get_ai_agent(deals_df, wo_df)
        if agent:
            with st.spinner("üß† Analyzing Monday.com Data..."):
                answer = ask_agent(agent, query)
                st.info(answer)
        else:
            st.error("Missing Groq API Key. Add GROQ_API_KEY to your Streamlit secrets or local .env file.")

# --- Action Panel ---
with side_col:
    st.subheader("üìë Quick Actions")
    if st.button("üöÄ Generate Leadership Summary", type="primary", use_container_width=True):
        st.write("**Executive Summary:**")
        if not deals_df.empty and not wo_df.empty:
            agent = get_ai_agent(deals_df, wo_df)
            if agent:
                with st.spinner("Generating executive insights..."):
                    prompt = """
                    Generate a concise 5-bullet executive Leadership Summary using precise data:
                    - Total pipeline value
                    - Expected revenue
                    - Top performing sector
                    - Work order execution efficiency (completion rate)
                    - Key risks (delays, incomplete data, stalled deals)
                    Format clearly with emojis.
                    """
                    summary = ask_agent(agent, prompt)
                    st.success(summary)
            else:
                st.error("Groq API Key needed for AI Summary.")
        else:
            st.warning("Insufficient data to generate summary.")

st.divider()

# --- Raw Data Review ---
with st.expander("üîç View Live Processed Data"):
    st.write("### üíº Deals Pipeline (Cleaned)")
    if not deals_df.empty:
        st.dataframe(deals_df, use_container_width=True)
    else:
        st.warning("No data retrieved from Deals Board.")
        
    st.write("### üõ†Ô∏è Work Orders (Cleaned)")
    if not wo_df.empty:
        st.dataframe(wo_df, use_container_width=True)
    else:
        st.warning("No data retrieved from Work Orders Board.")
